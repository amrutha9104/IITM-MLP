{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**(Common data for Q1 to Q5 graded questions)** \\\n",
        "Step 1: Download the dataset using following link: (https://drive.google.com/file/d/1v-uxWEgTI0GDCOTZOX3shUMkTf1a_CL7/view?usp=sharing)\n",
        "\n",
        "Step 2: Import the data in google colab using pd.read_csv().\n",
        "\n",
        "Step 3: Seperate features and target data in seperate variable X and Y.\n",
        "\n",
        "Step 4: Convert dataframe X and series y into array and save it in variable X_array,y_array.\n",
        "\n",
        "Step 5: Split the dataset using train_test_split. (Keep parameter test_size=0.3 and random_state=10).\n",
        "\n",
        "Step 6: Reshape the dataset in such a way that each entry of data has 90 samples.\n",
        "\n",
        "Step 7: Use SGD regressor as an estimator and partial_fit to fit the dataset on the model. (Set random_state=10)\n",
        "\n",
        "Step 8: Calculate different evaluation metrics value like mean_square_error, R2_score.\n",
        "\n",
        "Use the training set for fitting the model and use the test data to make the predictions.\n",
        "\n",
        "Note: No need to scale the data. It's already scaled."
      ],
      "metadata": {
        "id": "ROitMAKgWR4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) How many fetaures are there in the dataset?"
      ],
      "metadata": {
        "id": "XTejoG0MWX2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "data = pd.read_csv('/content/data_for_large_scale(Week 8 dataset).csv')\n",
        "\n",
        "X = data.drop('Target', axis=1)\n",
        "y = data['Target']\n",
        "\n",
        "X_array = X.values\n",
        "y_array = y.values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.3, random_state=10)\n",
        "\n",
        "samples_per_entry = 90\n",
        "num_entries_train = len(X_train) // samples_per_entry\n",
        "num_entries_test = len(X_test) // samples_per_entry\n",
        "\n",
        "X_train_reshaped = X_train[:num_entries_train * samples_per_entry].reshape(num_entries_train, samples_per_entry, -1)\n",
        "X_test_reshaped = X_test[:num_entries_test * samples_per_entry].reshape(num_entries_test, samples_per_entry, -1)\n",
        "y_train_reshaped = y_train[:num_entries_train * samples_per_entry].reshape(num_entries_train, samples_per_entry)\n",
        "y_test_reshaped = y_test[:num_entries_test * samples_per_entry].reshape(num_entries_test, samples_per_entry)\n",
        "\n",
        "estimator = SGDRegressor(random_state=10, warm_start=True)\n",
        "for i in range(X_train_reshaped.shape[0]):\n",
        "  estimator.partial_fit(X_train_reshaped[i].reshape(samples_per_entry, -1), y_train_reshaped[i])\n",
        "\n",
        "y_pred = estimator.predict(X_test_reshaped.reshape(num_entries_test * samples_per_entry, -1))\n",
        "\n",
        "mse = mean_squared_error(y_test_reshaped.reshape(num_entries_test * samples_per_entry), y_pred)\n",
        "r2 = r2_score(y_test_reshaped.reshape(num_entries_test * samples_per_entry), y_pred)\n",
        "\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "print(f\"Number of features: {X.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiYoX3_SWb3O",
        "outputId": "4764c2a0-516b-42de-ae51-7b730f012416"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.3058336488643974\n",
            "R-squared: 0.9999919793766233\n",
            "Number of features: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) What is the value of intercept you got after training the model using SGDRegressor?(select the closest answer)"
      ],
      "metadata": {
        "id": "iJXRAVUGX5BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Intercept: {estimator.intercept_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cobmhri4X9i0",
        "outputId": "3bf3e592-06f7-4dde-adcd-9a00d9fd9328"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept: [-0.0054532]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) What is the value of cofficient corresponding to \"feature-3\"you got after trainig the model using SGDRegressor? (select the closest answer)"
      ],
      "metadata": {
        "id": "UaUvVmAxX-nD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Coefficient for feature-3: {estimator.coef_[2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKuNKZOkYD-M",
        "outputId": "538557f0-3ab1-47ce-aac1-2e7f52c28fb5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficient for feature-3: 81.2376286796651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) What is the value of R2 score for test data"
      ],
      "metadata": {
        "id": "mdg6zPjjYIhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"R-squared: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHjQ9lKXYL73",
        "outputId": "563e147c-3400-417e-e0a8-21e2d497062b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared: 0.9999919793766233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) What is the value of cofficient corresponding to \"feature-5\" after 5th iteration."
      ],
      "metadata": {
        "id": "psVwryQ_YOk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = SGDRegressor(random_state=10, warm_start=True)\n",
        "coef_history = []\n",
        "\n",
        "for i in range(X_train_reshaped.shape[0]):\n",
        "  estimator.partial_fit(X_train_reshaped[i].reshape(samples_per_entry, -1), y_train_reshaped[i])\n",
        "  coef_history.append(estimator.coef_.copy()) # Store coefficients after each iteration\n",
        "\n",
        "print(f\"Coefficient for feature-5 after 5th iteration: {coef_history[4][4]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md-JjTtCYSam",
        "outputId": "edfdc5f7-6b21-4233-ce4d-0f5ed7e523cb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficient for feature-5 after 5th iteration: 56.05563939842212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Common data for Q6 to Q8 Graded questions)**\\\n",
        "This dataset was constructed by adding elevation information to a 2D road network in North Jutland, Denmark (covering a region of 185 x 135 km^2). Elevation values where extracted from a publicly available massive Laser Scan Point Cloud for Denmark. This 3D road network was eventually used for benchmarking various fuel and CO2 estimation algorithms. This dataset can be used by any applications that require to know very accurate elevation information of a road network to perform more accurate routing for eco-routing, cyclist routes etc. For the data mining and machine learning community, this dataset can be used as 'ground-truth' validation in spatial mining techniques and satellite image processing. It has no class labels,\n",
        "\n",
        "Use this dataset to guess some missing elevation information for some points on the road.\n",
        "\n",
        "Column names:\n",
        "\n",
        "OSM_ID: OpenStreetMap ID for each road segment or edge in the graph.\n",
        "\n",
        "LONGITUDE: Web Mercaptor (Google format) longitude\n",
        "\n",
        "LATITUDE: Web Mercaptor (Google format) latitude\n",
        "\n",
        "ALTITUDE: Height in meters.\n",
        "\n",
        "Load the dataset from link(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00246/3D_spatial_network.txt\"). Set parameter chunk size=20000 and iterator =True in pd.read_csv().\n",
        "\n",
        "NOTE: The above file doesn't have column names\n",
        "\n",
        "Scale your whole dataset first with standard scalar using partial_fit method. Then use SGDRegressor(random state=10) on the dataset and answer the following."
      ],
      "metadata": {
        "id": "4C_uPgBbYk9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Check how many total samples are there in the dataset?"
      ],
      "metadata": {
        "id": "5j-bnoCoY6R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "chunksize = 20000\n",
        "chunks = []\n",
        "for chunk in pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00246/3D_spatial_network.txt', chunksize=chunksize, iterator=True, header=None, names=['OSM_ID', 'LONGITUDE', 'LATITUDE', 'ALTITUDE']):\n",
        "    chunks.append(chunk)\n",
        "\n",
        "data = pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "if 'ALTITUDE' not in data.columns:\n",
        "    print(\"Error: 'ALTITUDE' column not found in the dataset.\")\n",
        "else:\n",
        "    X = data[['LONGITUDE', 'LATITUDE']]\n",
        "    y = data['ALTITUDE']\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
        "    sgd_regressor = SGDRegressor(random_state=10)\n",
        "    sgd_regressor.fit(X_scaled, y_scaled)\n",
        "    print(f\"Total number of samples in the dataset: {len(data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUf0f_AyY4TM",
        "outputId": "5c689e41-bd44-4ba2-d15d-05f777164bc5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of samples in the dataset: 434874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) What is the value of intercept after 7th iteration. (select the closest option)?"
      ],
      "metadata": {
        "id": "5X44CfcOZYgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = SGDRegressor(random_state=10, warm_start=True)\n",
        "intercept_history = []\n",
        "\n",
        "for i in range(X_train_reshaped.shape[0]):\n",
        "    estimator.partial_fit(X_train_reshaped[i].reshape(samples_per_entry, -1), y_train_reshaped[i])\n",
        "    intercept_history.append(estimator.intercept_)\n",
        "\n",
        "print(f\"{intercept_history[6]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLbgJo-XZcIu",
        "outputId": "deb8cdb8-76a0-4b67-9d46-9d5efcec0909"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-4.29515546]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) What is the value of the coefficient corresponding to the longitude feature after the 7th iteration? (select the closest option)."
      ],
      "metadata": {
        "id": "Uub5jEQAZuZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{coef_history[6][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yUvVqYkZ8eK",
        "outputId": "dfed7846-1457-4516-fabf-f62600f5c77a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44.2589484416221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Common data for Q9 to 11)**\\\n",
        "Load Iris datset on Colab and use KNN classifier to build the model Using following steps.\n",
        "\n",
        "Step 1: Load the dataset and split it using train_test_split by keeping: test_size= 0.2 random_state=10\n",
        "\n",
        "Step 2: Use Normalizer() as a scaling function to scale the data.\n",
        "\n",
        "Step 3: Use KNeighborsClassifier(K) as an estimator to predict the output."
      ],
      "metadata": {
        "id": "Mpbpst1ZaIek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9) Which of the following K value gives the best accuracy on test set.\n",
        "a) k=4 \\\n",
        "b) k=2 \\\n",
        "c) k=3 \\\n",
        "d) All K value given in the option gives same score."
      ],
      "metadata": {
        "id": "XSu2YZ73aMeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "\n",
        "scaler = Normalizer()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "k_values = [2, 3, 4]\n",
        "best_k = None\n",
        "best_accuracy = 0\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "    y_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy for k={k}: {accuracy}\")\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_k = k\n",
        "\n",
        "print(f\"\\nBest K value: {best_k} with accuracy: {best_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coor3GU9aIC3",
        "outputId": "577b90c1-b5e7-4eba-f3dd-8341c8fbc413"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for k=2: 0.9666666666666667\n",
            "Accuracy for k=3: 0.9666666666666667\n",
            "Accuracy for k=4: 0.9666666666666667\n",
            "\n",
            "Best K value: 2 with accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) What is the accuracy for k=3?"
      ],
      "metadata": {
        "id": "k_5uAkwTa4Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy for k=3: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsEGG9hQfocx",
        "outputId": "8e1c5ff9-a258-44eb-ca64-6a1e94e36f00"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for k=3: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11) Compute wieghted F1 score value for k=3.(Keep parameter average='weighted')"
      ],
      "metadata": {
        "id": "vUJaU920fuzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Weighted F1 score for k=3: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOwnd81lfyLf",
        "outputId": "517af265-17dd-46ce-e937-e0a419e52f33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted F1 score for k=3: 0.9671111111111111\n"
          ]
        }
      ]
    }
  ]
}